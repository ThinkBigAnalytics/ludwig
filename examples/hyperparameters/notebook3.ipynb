{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "from ludwig import LudwigModel\n",
    "import copy\n",
    "import ray\n",
    "from ludwig.utils.misc import merge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bm255022/Projects/Teradata/ludwig/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open(\"titanic_full.yaml\", 'r') as stream:\n",
    "    base_model = yaml.load(stream)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base should contain special markup so we know what parameters need to be updated.\n",
    "\n",
    "def build_trial(base, config):\n",
    "    combiner = base['combiner']\n",
    "    training = base['training']\n",
    "    \n",
    "    \n",
    "    combiner = merge_dict(combiner, {'num_fc_layers': config['num_fc_layers']})\n",
    "    training = merge_dict(training, {'batch_size': config['batch_size']})\n",
    "    \n",
    "    new_model_def = {'input_features': base['input_features'], \n",
    "                 'output_features': base['output_features'], \n",
    "                 'combiner': combiner, \n",
    "                 'training': training}\n",
    "    \n",
    "    return new_model_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/Users/bm255022/Projects/Teradata/ludwig/examples/hyperparameters/titanic.hdf5'\n",
    "metadata = '/Users/bm255022/Projects/Teradata/ludwig/examples/hyperparameters/titanic.json'\n",
    "\n",
    "def train(base, config, reporter):\n",
    "    \n",
    "    new_model_def = build_trial(base, config)\n",
    "    model = LudwigModel(new_model_def)\n",
    "    train_stats = model.train(data_hdf5=data, train_set_metadata_json=metadata)\n",
    "    return reporter(mean_accuracy=train_stats['validation']['Survived']['accuracy'][-1], done=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import register_trainable, grid_search, run_experiments\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "grid_search_space = {\n",
    "    'num_fc_layers': grid_search([1,2,3,4]),\n",
    "    'batch_size': grid_search([4,16,32,64,128])\n",
    "}\n",
    "\n",
    "register_trainable('train', lambda cfg, rptr: train(base_model, cfg, rptr))\n",
    "run_experiments({'my_experiment': {\n",
    "    'run': 'train',\n",
    "    'stop': {'mean_accuracy': 0.9},\n",
    "    'config': grid_search_space}\n",
    "    })\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a more eleborate approach to specifying parameters to search over.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 1, doesn't handle lists.  extracts parameters that we want to search over.  \n",
    "\n",
    "\n",
    "import re\n",
    "pattern = \"^{{.*}}\"\n",
    "\n",
    "def get_keys(dct, path=\"\"):\n",
    "    parameters = []\n",
    "    for k, v in dct.items():\n",
    "        if isinstance(dct[k], dict):\n",
    "            p = get_keys(dct[k], path+k+\"->\" )\n",
    "            if p:\n",
    "                for l in p:\n",
    "                    parameters.append(l)\n",
    "            \n",
    "        elif isinstance(dct[k], str):\n",
    "            if re.match(pattern, dct[k], flags=0) is not None:\n",
    "                parameters.append([path + k,dct[k]])\n",
    "       \n",
    "    return parameters\n",
    "\n",
    "#updates parameters...doens't handle lists\n",
    "\n",
    "def update_param(dct, path, value):\n",
    "    if len(path) == 1:\n",
    "        dct[path[0]] = value\n",
    "    else:\n",
    "        update_param(dct[path[0]], path[1:], value)\n",
    "        \n",
    "def build_model(base_model, config):\n",
    "    for k, v in config.items():\n",
    "        p = k.split('->')\n",
    "        update_param(base_model, p, v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bm255022/Projects/Teradata/ludwig/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'combiner': {'fc_size': '{{[24,48,64]}}',\n",
       "  'num_fc_layers': 1,\n",
       "  'type': 'concat'},\n",
       " 'input_features': [{'name': 'Pclass', 'type': 'category'},\n",
       "  {'name': 'Sex', 'type': 'category'},\n",
       "  {'missing_value_strategy': 'fill_with_mean',\n",
       "   'name': 'Age',\n",
       "   'type': 'numerical'},\n",
       "  {'name': 'SibSp', 'type': 'numerical'},\n",
       "  {'name': 'Parch', 'type': 'numerical'},\n",
       "  {'missing_value_strategy': 'fill_with_mean',\n",
       "   'name': 'Fare',\n",
       "   'type': 'numerical'},\n",
       "  {'name': 'Embarked', 'representation': 'sparse', 'type': 'category'}],\n",
       " 'output_features': [{'name': 'Survived', 'type': 'binary'}],\n",
       " 'training': {'batch_size': '{{[8,16,32,64]}}',\n",
       "  'bucketing_field': None,\n",
       "  'decay': False,\n",
       "  'decay_rate': 0.96,\n",
       "  'decay_steps': 10000,\n",
       "  'dropout_rate': 0.0,\n",
       "  'early_stop': 5,\n",
       "  'epochs': 100,\n",
       "  'gradient_clipping': None,\n",
       "  'increase_batch_size_on_plateau': 0,\n",
       "  'increase_batch_size_on_plateau_max': 512,\n",
       "  'increase_batch_size_on_plateau_patience': 5,\n",
       "  'increase_batch_size_on_plateau_rate': 2,\n",
       "  'learning_rate': 0.001,\n",
       "  'learning_rate_warmup_epochs': 5,\n",
       "  'optimizer': {'beta1': 0.9,\n",
       "   'beta2': 0.999,\n",
       "   'epsilon': 1e-08,\n",
       "   'type': '{{[adam,sgd]}}'},\n",
       "  'reduce_learning_rate_on_plateau': 0,\n",
       "  'reduce_learning_rate_on_plateau_patience': 5,\n",
       "  'reduce_learning_rate_on_plateau_rate': 0.5,\n",
       "  'regularization_lambda': 0,\n",
       "  'regularizer': 'l2',\n",
       "  'staircase': False,\n",
       "  'validation_field': 'combined',\n",
       "  'validation_measure': 'loss'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"titanic_full_h.yaml\", 'r') as stream:\n",
    "    base_model_h = yaml.load(stream)\n",
    "base_model_h\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['combiner->fc_size', '{{[24,48,64]}}'],\n",
       " ['training->batch_size', '{{[8,16,32,64]}}'],\n",
       " ['training->optimizer->type', '{{[adam,sgd]}}']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = get_keys(base_model_h)\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'combiner': {'fc_size': 48, 'num_fc_layers': 1, 'type': 'concat'},\n",
       " 'input_features': [{'name': 'Pclass', 'type': 'category'},\n",
       "  {'name': 'Sex', 'type': 'category'},\n",
       "  {'missing_value_strategy': 'fill_with_mean',\n",
       "   'name': 'Age',\n",
       "   'type': 'numerical'},\n",
       "  {'name': 'SibSp', 'type': 'numerical'},\n",
       "  {'name': 'Parch', 'type': 'numerical'},\n",
       "  {'missing_value_strategy': 'fill_with_mean',\n",
       "   'name': 'Fare',\n",
       "   'type': 'numerical'},\n",
       "  {'name': 'Embarked', 'representation': 'sparse', 'type': 'category'}],\n",
       " 'output_features': [{'name': 'Survived', 'type': 'binary'}],\n",
       " 'training': {'batch_size': 64,\n",
       "  'bucketing_field': None,\n",
       "  'decay': False,\n",
       "  'decay_rate': 0.96,\n",
       "  'decay_steps': 10000,\n",
       "  'dropout_rate': 0.0,\n",
       "  'early_stop': 5,\n",
       "  'epochs': 100,\n",
       "  'gradient_clipping': None,\n",
       "  'increase_batch_size_on_plateau': 0,\n",
       "  'increase_batch_size_on_plateau_max': 512,\n",
       "  'increase_batch_size_on_plateau_patience': 5,\n",
       "  'increase_batch_size_on_plateau_rate': 2,\n",
       "  'learning_rate': 0.001,\n",
       "  'learning_rate_warmup_epochs': 5,\n",
       "  'optimizer': {'beta1': 0.9,\n",
       "   'beta2': 0.999,\n",
       "   'epsilon': 1e-08,\n",
       "   'type': 'adam'},\n",
       "  'reduce_learning_rate_on_plateau': 0,\n",
       "  'reduce_learning_rate_on_plateau_patience': 5,\n",
       "  'reduce_learning_rate_on_plateau_rate': 0.5,\n",
       "  'regularization_lambda': 0,\n",
       "  'regularizer': 'l2',\n",
       "  'staircase': False,\n",
       "  'validation_field': 'combined',\n",
       "  'validation_measure': 'loss'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'combiner->fc_size': 48,\n",
    "          'training->batch_size': 64,\n",
    "          'training->optimizer->type': 'adam'\n",
    "         }\n",
    "\n",
    "build_model(base_model_h, config)\n",
    "base_model_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
