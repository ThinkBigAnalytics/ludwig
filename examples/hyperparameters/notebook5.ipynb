{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "from ludwig import LudwigModel\n",
    "import copy\n",
    "import ray\n",
    "from ludwig.utils.misc import merge_dict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. start with titanic.csv file from kaggle\n",
    "2. create a simple ludwig model yaml file\n",
    "3. run it through ludwig to generate the hdf5 and metadata file.\n",
    "4. create a yaml file with all the parameters you want to search over.\n",
    "5. annotate using simple {{[1,2,3]}} type annotation.  this can probably be improved and better generalized.\n",
    "6. follow the rest of the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combiner: {fc_size: \"{{[24,48,64]}}\", num_fc_layers: 1, type: concat}\r\n",
      "input_features:\r\n",
      "- {name: Pclass, type: category}\r\n",
      "- {name: Sex, type: category}\r\n",
      "- {name: Age, type: numerical,missing_value_strategy: fill_with_mean}\r\n",
      "- {name: SibSp, type: numerical}\r\n",
      "- {name: Parch, type: numerical}\r\n",
      "- {name: Fare, type: numerical, missing_value_strategy: fill_with_mean}\r\n",
      "- {name: Embarked, representation: \"{{[sparse, dense]}}\", type: category}\r\n",
      "output_features:\r\n",
      "- {name: Survived, type: binary}\r\n",
      "training:\r\n",
      "  batch_size: \"{{[8,16,32,64]}}\"\r\n",
      "  bucketing_field: null\r\n",
      "  decay: false\r\n",
      "  decay_rate: 0.96\r\n",
      "  decay_steps: 10000\r\n",
      "  dropout_rate: 0.0\r\n",
      "  early_stop: 5\r\n",
      "  epochs: 100\r\n",
      "  gradient_clipping: null\r\n",
      "  increase_batch_size_on_plateau: 0\r\n",
      "  increase_batch_size_on_plateau_max: 512\r\n",
      "  increase_batch_size_on_plateau_patience: 5\r\n",
      "  increase_batch_size_on_plateau_rate: 2\r\n",
      "  learning_rate: 0.001\r\n",
      "  learning_rate_warmup_epochs: 5\r\n",
      "  optimizer: {beta1: 0.9, beta2: 0.999, epsilon: 1.0e-08, type: adam}\r\n",
      "  reduce_learning_rate_on_plateau: 0\r\n",
      "  reduce_learning_rate_on_plateau_patience: 5\r\n",
      "  reduce_learning_rate_on_plateau_rate: 0.5\r\n",
      "  regularization_lambda: 0\r\n",
      "  regularizer: l2\r\n",
      "  staircase: false\r\n",
      "  validation_field: combined\r\n",
      "  validation_measure: loss\r\n"
     ]
    }
   ],
   "source": [
    "!cat titanic.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_keys_from_dict will return the following (path, value) pairs:\n",
    "['combiner->fc_size', '{{[24,48,64]}}'], \n",
    "['input_features->[6]->representation', '{{[sparse, dense]}}'], \n",
    "['training->batch_size', '{{[8,16,32,64]}}']\n",
    "\n",
    "note that input_features->[6] references the 6th element of the input_features list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_pattern = \"^{{.*}}$\"\n",
    "\n",
    "def get_keys_from_list(l, path=\"\"):\n",
    "    parameters = []\n",
    "    for index, v in enumerate(l):\n",
    "        if isinstance(l[index], str):\n",
    "             if re.match(search_pattern, l[index], flags=0) is not None:\n",
    "                parameters.append([path + \"[\" + index + \"]\", v])\n",
    "\n",
    "        elif isinstance(l[index], dict):\n",
    "            p = get_keys_from_dict(l[index], path+ \"[\" + str(index) + \"]\" +\"->\" )\n",
    "            parameters.extend(p)\n",
    "        \n",
    "        elif isinstance(l[index], list):\n",
    "            p = get_keys_from_list(l[index], path+ \"[\" + str(index) + \"]\" +\"->\" )\n",
    "            parameters.extend(p)\n",
    "            \n",
    "    return parameters\n",
    "\n",
    "\n",
    "def get_keys_from_dict(dct, path=\"\"):\n",
    "    parameters = []\n",
    "    for k, v in dct.items():\n",
    "        if isinstance(dct[k], str):\n",
    "            if re.match(search_pattern, dct[k], flags=0) is not None:\n",
    "                parameters.append([path + k,dct[k]])\n",
    "\n",
    "        elif isinstance(dct[k], dict):\n",
    "            p = get_keys_from_dict(dct[k], path+k+\"->\" )\n",
    "            parameters.extend(p)\n",
    "            \n",
    "\n",
    "        elif isinstance(dct[k], list):\n",
    "            p = get_keys_from_list(dct[k], path+k+\"->\" )\n",
    "            parameters.extend(p)\n",
    "            \n",
    "    return parameters\n",
    "\n",
    "\n",
    "list_index_pattern = \"^\\[\\d+\\]$\"\n",
    "\n",
    "def set_search_param(dct, path, value):\n",
    "    if len(path) == 1:\n",
    "        dct[path[0]] = value\n",
    "    else:\n",
    "        l = re.match(list_index_pattern, path[0], flags=0)\n",
    "        if l is not None and isinstance(dct, list):\n",
    "            index = int(l.group(0)[1:-1])\n",
    "            set_search_param(dct[index], path[1:], value)\n",
    "        else:\n",
    "            set_search_param(dct[path[0]], path[1:], value)\n",
    "\n",
    "\n",
    "def build_model(base_model, config):\n",
    "    for k, v in config.items():\n",
    "        p = k.split('->')\n",
    "        set_search_param(base_model, p, v)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use full path for Ray\n",
    "data = '/Users/bm255022/Projects/Teradata/ludwig/examples/hyperparameters/titanic.hdf5'\n",
    "metadata = '/Users/bm255022/Projects/Teradata/ludwig/examples/hyperparameters/titanic.json'\n",
    "\n",
    "def train(base, config, reporter):\n",
    "    new_model_def = build_model(base, config)\n",
    "    model = LudwigModel(new_model_def)\n",
    "    train_stats = model.train(data_hdf5=data, train_set_metadata_json=metadata)\n",
    "    return reporter(mean_accuracy=np.sort(train_stats['validation']['Survived']['accuracy'])[-1], done=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import grid_search\n",
    "\n",
    "def build_search_space(annotated_model):\n",
    "    pattern = \"^{{(.*)}}$\"\n",
    "    grid_search_space = {}\n",
    "    keys = get_keys_from_dict(annotated_model)\n",
    "    print(keys)\n",
    "    for a in keys:\n",
    "        grid_search_space[a[0]]= grid_search(yaml.load(re.match(pattern, a[1], flags=0)[1]))\n",
    "\n",
    "    return grid_search_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import register_trainable, grid_search, run_experiments\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "with open(\"titanic.yaml\", 'r') as stream:\n",
    "    annotated_model = yaml.load(stream)\n",
    "\n",
    "grid_search_space = build_search_space(annotated_model)\n",
    "\n",
    "register_trainable('train', lambda cfg, rptr: train(annotated_model, cfg, rptr))\n",
    "run_experiments({'titanic': {\n",
    "    'run': 'train',\n",
    "    'stop': {'mean_accuracy': 0.9},\n",
    "    'config': grid_search_space}\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
