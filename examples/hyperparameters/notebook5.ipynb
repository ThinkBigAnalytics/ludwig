{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "from ludwig import LudwigModel\n",
    "import copy\n",
    "import ray\n",
    "from ludwig.utils.misc import merge_dict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"^{{.*}}$\"\n",
    "list_index_pattern = \"^\\[\\d+\\]$\"\n",
    "\n",
    "\n",
    "def get_keys_from_list(l, path=\"\"):\n",
    "    parameters = []\n",
    "\n",
    "    for index, v in enumerate(l):\n",
    "        if isinstance(l[index], str):\n",
    "             if re.match(pattern, l[index], flags=0) is not None:\n",
    "                parameters.append([path + \"[\" + index + \"]\", v])\n",
    "\n",
    "        elif isinstance(l[index], dict):\n",
    "            p = get_keys_from_dict(l[index], path+ \"[\" + str(index) + \"]\" +\"->\" )\n",
    "            if p:\n",
    "                for l in p:\n",
    "                    parameters.append(l)\n",
    "        elif isinstance(l[index], list):\n",
    "            p = get_keys_from_list(l[index], path+ \"[\" + str(index) + \"]\" +\"->\" )\n",
    "            if p:\n",
    "                for l in p:\n",
    "                    parameters.append(l)\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def get_keys_from_dict(dct, path=\"\"):\n",
    "    parameters = []\n",
    "    for k, v in dct.items():\n",
    "        if isinstance(dct[k], str):\n",
    "            if re.match(pattern, dct[k], flags=0) is not None:\n",
    "                parameters.append([path + k,dct[k]])\n",
    "\n",
    "        elif isinstance(dct[k], dict):\n",
    "            p = get_keys_from_dict(dct[k], path+k+\"->\" )\n",
    "            if p:\n",
    "                for l in p:\n",
    "                    parameters.append(l)\n",
    "\n",
    "        elif isinstance(dct[k], list):\n",
    "            p = get_keys_from_list(dct[k], path+k+\"->\" )\n",
    "            if p:\n",
    "                for l in p:\n",
    "                    parameters.append(l)\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n",
    "def update_param(dct, path, value):\n",
    "    if len(path) == 1:\n",
    "        dct[path[0]] = value\n",
    "    else:\n",
    "        l = re.match(list_index_pattern, path[0], flags=0)\n",
    "        if l is not None and isinstance(dct, list):\n",
    "            index = int(l.group(0)[1:-1])\n",
    "            update_param(dct[index], path[1:], value)\n",
    "        else:\n",
    "             update_param(dct[path[0]], path[1:], value)\n",
    "\n",
    "\n",
    "def build_model(base_model, config):\n",
    "    for k, v in config.items():\n",
    "        p = k.split('->')\n",
    "        update_param(base_model, p, v)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import grid_search\n",
    "\n",
    "def build_search_space(annotated_model):\n",
    "    pattern = \"^{{(.*)}}$\"\n",
    "    grid_search_space = {}\n",
    "    keys = get_keys_from_dict(annotated_model)\n",
    "    for a in keys:\n",
    "        grid_search_space[a[0]]= grid_search(yaml.load(re.match(pattern, a[1], flags=0)[1]))\n",
    "\n",
    "    return grid_search_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use full path for Ray\n",
    "data = '/Users/bm255022/Projects/Teradata/ludwig/examples/hyperparameters/titanic.hdf5'\n",
    "metadata = '/Users/bm255022/Projects/Teradata/ludwig/examples/hyperparameters/titanic.json'\n",
    "\n",
    "def train(base, config, reporter):\n",
    "    new_model_def = build_model(base, config)\n",
    "    model = LudwigModel(new_model_def)\n",
    "    train_stats = model.train(data_hdf5=data, train_set_metadata_json=metadata)\n",
    "    return reporter(mean_accuracy=train_stats['validation']['Survived']['accuracy'][-1], done=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import register_trainable, grid_search, run_experiments\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "with open(\"titanic.yaml\", 'r') as stream:\n",
    "    annotated_model = yaml.load(stream)\n",
    "\n",
    "grid_search_space = build_search_space(annotated_model)\n",
    "register_trainable('train', lambda cfg, rptr: train(annotated_model, cfg, rptr))\n",
    "run_experiments({'my_experiment': {\n",
    "    'run': 'train',\n",
    "    'stop': {'mean_accuracy': 0.9},\n",
    "    'config': grid_search_space}\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
